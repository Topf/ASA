<!-- Generated by SpecStory -->

# Explain the orchestrator_agent components (2025-06-15 13:36:38)

_**User**_

Can you please explain how this orchestrator_agent works? Explain every part of it.

---

_**Assistant**_



---

I'll break down the orchestrator_agent.py file and explain how each part works. This appears to be a social media growth system that uses AI agents to select platforms and create content strategies.

## **1. Imports and Setup**

```12:8:orchestrator_agent.py
from smolagents import ToolCallingAgent, LiteLLMModel, tool
import yaml
import os
import json
from typing import Dict, List, Any

# Set up your Anthropic API key
os.environ["ANTHROPIC_API_KEY"] = "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"
```

- Uses `smolagents` framework for creating AI agents
- Imports necessary libraries for YAML parsing, file operations, and JSON handling
- Sets up the Anthropic API key for Claude access

## **2. Prompt Loading System**

```11:29:orchestrator_agent.py
def load_prompts():
    """Load all prompt files from the prompts directory."""
    prompts = {}
    
    # Load platforms agent prompts
    with open('prompts/platforms_agent_prompts.yaml', 'r') as f:
        prompts['platforms_agent'] = yaml.safe_load(f)
    
    # Load platform-specific prompts
    platform_files = {
        'tiktok_agent': 'prompts/tiktok_prompts.yaml',
        'linkedin_agent': 'prompts/linkedin_prompts.yaml',
        'reddit_agent': 'prompts/reddit_prompts.yaml',
        'twitter_agent': 'prompts/twitter_prompts.yaml',
        'instagram_agent': 'prompts/instagram_prompts.yaml'
    }
    
    for agent_key, file_path in platform_files.items():
        with open(file_path, 'r') as f:
            prompts[agent_key] = yaml.safe_load(f)
    
    return prompts
```

This function centralizes prompt management by:
- Loading platform selector prompts from `platforms_agent_prompts.yaml`
- Loading individual platform-specific prompts (TikTok, LinkedIn, Reddit, Twitter/X, Instagram)
- Returning a dictionary with all prompts organized by agent type

## **3. Model Configuration**

```32:39:orchestrator_agent.py
# Create our LiteLLM model for Anthropic Claude 3.5 Sonnet
model = LiteLLMModel(
    model_id="anthropic/claude-3-5-sonnet-latest",
    api_key=os.environ["ANTHROPIC_API_KEY"],
    max_tokens=4096,
    temperature=0.5,
)
```

Sets up the AI model with:
- Claude 3.5 Sonnet as the language model
- 4096 token limit for responses
- Temperature of 0.5 for balanced creativity/consistency

## **4. Platform Content Creation Tool**

```41:86:orchestrator_agent.py
@tool
def create_platform_content(platform: str, company_description: str, target_audience: str) -> str:
```

This is the core content generation function that:

**Platform Mapping:**
```55:65:orchestrator_agent.py
    platform_map = {
        "tiktok": "tiktok_agent",
        "linkedin": "linkedin_agent", 
        "reddit": "reddit_agent",
        "twitter": "twitter_agent",
        "x": "twitter_agent",
        "twitter/x": "twitter_agent",
        "instagram": "instagram_agent",
    }
```

**Dynamic Agent Creation:**
```67:86:orchestrator_agent.py
    # Get platform-specific prompts
    agent_prompts = prompt_templates.get(platform_key, {})
    system_prompt = agent_prompts.get('system_prompt', f"You are a {platform} content strategist.")
    content_prompt = agent_prompts.get('content_prompt', 
        f"Create 3 content ideas for {platform}.\nCOMPANY: {company_description}\nAUDIENCE: {target_audience}")
    
    # Format the prompt
    formatted_prompt = content_prompt.format(
        company_description=company_description,
        target_audience=target_audience,
    )
    
    # Create and run platform agent
    platform_agent = ToolCallingAgent(
        tools=[],
        model=model,
        system_prompt=system_prompt
    )
    
    return platform_agent.run(formatted_prompt)
```

For each platform, it:
- Maps platform names to agent configurations
- Retrieves platform-specific prompts
- Creates a specialized agent with the appropriate system prompt
- Generates content strategy tailored to that platform

## **5. Platform Selection System**

```88:112:orchestrator_agent.py
def select_platforms(company_description: str, target_audience: str) -> Dict[str, Any]:
    """Select 3 optimal social media platforms for the company and audience."""
    
    # Create platform selector agent
    selector_agent = ToolCallingAgent(
        tools=[],
        model=model,
        system_prompt=prompt_templates['platforms_agent']['system_prompt']
    )
    
    # Format selection prompt
    selection_prompt = prompt_templates['platforms_agent']['selection_prompt'].format(
        company_description=company_description,
        target_audience=target_audience
    )
    
    result = selector_agent.run(selection_prompt)
    
    # Parse JSON from result
    try:
        start_idx = result.find('{')
        end_idx = result.rfind('}') + 1
        if start_idx != -1 and end_idx != 0:
            json_str = result[start_idx:end_idx]
            return json.loads(json_str)
        else:
            return {"error": "Could not parse platform selection", "raw_response": result}
    except json.JSONDecodeError:
        return {"error": "Invalid JSON in platform selection", "raw_response": result}
```

This function:
- Creates a specialized platform selection agent
- Analyzes company and audience to recommend 3 optimal platforms
- Extracts and parses JSON response containing platform recommendations
- Handles parsing errors gracefully

## **6. Main Orchestration Function**

```114:164:orchestrator_agent.py
def run_growth_system(company_description: str, target_audience: str) -> Dict[str, Any]:
    """
    Main function to run the complete Growth Agentic System.
    Simple orchestration of the entire workflow.
    """
```

This is the main workflow coordinator that:

**Step 1 - Platform Selection:**
```124:128:orchestrator_agent.py
    # Step 1: Select platforms
    print("\nðŸ“± Selecting optimal social media platforms...")
    platform_selection = select_platforms(company_description, target_audience)
    
    if "error" in platform_selection:
        return platform_selection
```

**Step 2 - Content Generation:**
```130:151:orchestrator_agent.py
    # Step 2: Generate content for each platform
    print("\nðŸ¤– Creating content strategies...")
    content_strategies = {}
    
    for platform_info in platform_selection['selected_platforms']:
        platform = platform_info['platform']
        priority = platform_info['priority']
        
        print(f"ðŸŽ¬ Creating content for {platform} (Priority {priority})...")
        
        content_strategy = create_platform_content(
            platform=platform,
            company_description=company_description,
            target_audience=target_audience
        )
        
        content_strategies[platform] = {
            'priority': priority,
            'content_strategy': content_strategy
        }
```

**Final Output:**
```153:156:orchestrator_agent.py
    return {
        'selected_platforms': platform_selection['selected_platforms'],
        'content_strategies': content_strategies
    }
```

## **How It All Works Together**

1. **Input**: Company description and target audience
2. **Platform Selection**: AI agent analyzes inputs and selects 3 optimal social media platforms
3. **Content Creation**: For each selected platform, a specialized agent creates tailored content strategies
4. **Output**: Complete social media growth plan with platform priorities and content strategies

The system is modular and extensible - you can easily add new platforms by creating new prompt files and updating the platform mapping. Each platform gets its own specialized AI agent with platform-specific knowledge and prompts.

---

_**User**_

Why are we passing just the first 50 characters of the company description? Dont edit any code.

---

_**Assistant**_



---

Looking at that code snippet, the `[:50]` is used to **truncate the display output for better readability** in the console logs.

Here's why this makes sense:

1. **Clean Console Output**: Company descriptions and target audience descriptions can be quite long (sometimes several sentences or paragraphs). If you printed the full text, it would clutter the console and make it hard to follow the system's progress.

2. **Preview Purpose**: The print statements are meant to show what inputs the system is working with, not display the complete content. The first 50 characters give you enough context to understand what company/audience is being processed.

3. **Visual Formatting**: The `...` at the end indicates there's more content, making it clear this is a preview rather than the complete text.

For example, instead of seeing this cluttered output:
```
ðŸ“Š Company: We are a sustainable fashion startup that creates eco-friendly clothing using recycled materials and focuses on ethical manufacturing practices while targeting environmentally conscious millennials and Gen Z consumers who value sustainability and social responsibility in their purchasing decisions...
```

You get this clean preview:
```
ðŸ“Š Company: We are a sustainable fashion startup that create...
```

The **full** company description and target audience are still passed to the AI agents for processing - this truncation only affects what's displayed in the console for monitoring purposes. It's a UX consideration to keep the logs readable while the system runs.

---

_**User**_

great. how do I test if it works?

---

_**Assistant**_



---

Let me check what's already set up in the main app.py file to see how you can test the orchestrator system.

---

Read file: app.py

---

Perfect! There's already a test setup in `app.py`. Here's how you can test if the orchestrator works:

## **Method 1: Run the Existing Test (Recommended)**

Simply run the main app file:

---

```bash
cd /Users/manfredi.bernardi/Documents/ASA && python app.py
```

---

_**User**_

  File "/Users/manfredi.bernardi/Documents/ASA/app.py", line 1, in <module>
    from platform_agent import run_growth_system
ModuleNotFoundError: No module named 'platform_agent'

---

_**Assistant**_



---

I see the issue! The import in `app.py` is incorrect. It's trying to import from `platform_agent` but the actual file is `orchestrator_agent.py`. Let me fix this:

---



---

Now let's test if it works:

---

```bash
python app.py
```

---

_**User**_

(hackathon-env) manfredi.bernardi@Manfredi-Bernardi-KGY1C6P22C ASA % python3 app.py                   
Traceback (most recent call last):
  File "/Users/manfredi.bernardi/Documents/ASA/hackathon-env/lib/python3.13/site-packages/smolagents/models.py", line 1025, in create_client
    import litellm
ModuleNotFoundError: No module named 'litellm'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/manfredi.bernardi/Documents/ASA/app.py", line 1, in <module>
    from platforms_agent import run_growth_system
  File "/Users/manfredi.bernardi/Documents/ASA/platforms_agent.py", line 37, in <module>
    model = LiteLLMModel(
        model_id="anthropic/claude-3-5-sonnet-latest",
    ...<2 lines>...
        temperature=0.5,
    )
  File "/Users/manfredi.bernardi/Documents/ASA/hackathon-env/lib/python3.13/site-packages/smolagents/models.py", line 1015, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        model_id=model_id,
        ^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/Users/manfredi.bernardi/Documents/ASA/hackathon-env/lib/python3.13/site-packages/smolagents/models.py", line 965, in __init__
    self.client = client or self.create_client()
                            ~~~~~~~~~~~~~~~~~~^^
  File "/Users/manfredi.bernardi/Documents/ASA/hackathon-env/lib/python3.13/site-packages/smolagents/models.py", line 1027, in create_client
    raise ModuleNotFoundError(
        "Please install 'litellm' extra to use LiteLLMModel: `pip install 'smolagents[litellm]'`"
    ) from e
ModuleNotFoundError: Please install 'litellm' extra to use LiteLLMModel: `pip install 'smolagents[litellm]'`
(hackathon-env) manfredi.bernardi@Manfredi-Bernardi-KGY1C6P22C ASA % pip install LiteLLMModel
ERROR: Could not find a version that satisfies the requirement LiteLLMModel (from versions: none)

[notice] A new release of pip is available: 25.0.1 -> 25.1.1
[notice] To update, run: pip install --upgrade pip
ERROR: No matching distribution found for LiteLLMModel


---



---

_**Assistant**_



---

You need to install the `litellm` extra for `smolagents`. The error message shows exactly what to install:

---

```bash
pip install 'smolagents[litellm]'
```

---

_**User**_

[notice] To update, run: pip install --upgrade pip
(hackathon-env) manfredi.bernardi@Manfredi-Bernardi-KGY1C6P22C ASA % python3 app.py                   
ðŸ§ª Testing Growth Agentic System...
ðŸš€ Starting Growth Agentic System...
ðŸ“Š Company: A sustainable fashion startup that creates eco-fri...
ðŸŽ¯ Audience: Environmentally conscious millennials and Gen Z (a...

ðŸ“± Selecting optimal social media platforms...
Traceback (most recent call last):
  File "/Users/manfredi.bernardi/Documents/ASA/app.py", line 36, in <module>
    main()
    ~~~~^^
  File "/Users/manfredi.bernardi/Documents/ASA/app.py", line 12, in main
    result = run_growth_system(test_company, test_audience)
  File "/Users/manfredi.bernardi/Documents/ASA/platforms_agent.py", line 135, in run_growth_system
    platform_selection = select_platforms(company_description, target_audience)
  File "/Users/manfredi.bernardi/Documents/ASA/platforms_agent.py", line 98, in select_platforms
    selector_agent = ToolCallingAgent(
        tools=[],
        model=model,
        system_prompt=prompt_templates['platforms_agent']['system_prompt']
    )
  File "/Users/manfredi.bernardi/Documents/ASA/hackathon-env/lib/python3.13/site-packages/smolagents/agents.py", line 1176, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        tools=tools,
        ^^^^^^^^^^^^
    ...<3 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
TypeError: MultiStepAgent.__init__() got an unexpected keyword argument 'system_prompt'
(hackathon-env) manfredi.bernardi@Manfredi-Bernardi-KGY1C6P22C ASA % 


---

_**Assistant**_



---

There's an issue with how the `ToolCallingAgent` is being initialized. The `system_prompt` parameter isn't being accepted. Let me check the current implementation in the platforms_agent.py file:

---

Read file: platforms_agent.py

---

I can see the issue. The `ToolCallingAgent` in the current version doesn't accept `system_prompt` as a parameter. Let me check what the correct way to initialize it is by looking at the smolagents documentation or trying a different approach. Let me fix this by modifying how the agents are created:

---



---



---

Now let's test if it works:

---



---



---

